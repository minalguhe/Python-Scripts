#!/usr/bin/python
import csv
import requests
import time
from akamai.edgegrid import EdgeGridAuth, EdgeRc
from urllib.parse import urljoin

edgerc = EdgeRc('~/.edgerc')
section = 'default' # Section in edgerc file
baseurl = 'https://%s' % edgerc.get(section, 'host') # Extracting hostname from edgerc file

with open('<filename.csv>', 'r') as f: #Replace <filename.csv> with path+filename
	reader = csv.reader(f)
	data = list(reader) # creating the initial list of all URLs from the CSV

total_count = len(data) # checking the length of the list created
new_data = []

# Creating list of comma separated URLs
for n in range(0, total_count):
	obj_data = data[n]
	new_data.append(obj_data[0])

# Function to purge using URLs (200 at a time)
def purge(): 
	N = 0 
	# Variable for tracking purge rounds
	purge_round = 0
	# --- EDIT HERE --- Number of objects to purge each round
	purge_objects = 200
	# Number of times to loop based on total_count vs purge_objects
	loop = int(total_count / purge_objects) + (total_count % purge_objects > 0)
	print (loop)
	if N <= total_count:
		for i in range(N, loop): # creating for loop to purge 200 URLs at once
			payload = {"objects": new_data[N:N + purge_objects]}
			headers = {
    			"Accept": "application/json",
    			"Content-Type": "application/json"
			}
			s = requests.Session()
			s.auth = EdgeGridAuth.from_edgerc(edgerc, section)
			result = s.post(urljoin(baseurl, '/ccu/v3/delete/url/<network>'), json=payload, headers=headers) #Replace <network> with 'staging' or 'production'
			N = N + purge_objects
			purge_round = purge_round + 1
			# Output showing API call response and objects purged in each call.
			print("------------------ROUND ",purge_round,"------------------")
			print("")
			print("---API RESPONSE---")
			print(result.text)
			print("---PAYLOAD---")
			print(payload)
			print("")
		

purge() # Function call
